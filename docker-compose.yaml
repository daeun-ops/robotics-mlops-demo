version: "3.9"

services:
  airflow:
    image: apache/airflow:2.9.3
    container_name: airflow
    restart: unless-stopped
    env_file: .env
    environment:
      - _PIP_ADDITIONAL_REQUIREMENTS=
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - AIRFLOW__CORE__FERNET_KEY=NOT_NEEDED_FOR_LOCAL
      # MLflow 연결 정보 (DAG의 venv task에도 동일핫게 주입)
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    command: bash -lc "airflow db init && airflow users create --username $$AIRFLOW_ADMIN_USER --firstname a --lastname b --role Admin --email a@b.c --password $$AIRFLOW_ADMIN_PASSWORD || true && airflow standalone"
    volumes:
      - ./data-pipeline-airflow/dags:/opt/airflow/dags
    ports:
      - "8080:8080"
    depends_on:
      - mlflow
      - minio

  mlflow:
    build:
      context: ./training-mlflow/tracking_server
    container_name: mlflow
    restart: unless-stopped
    env_file: .env
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
    volumes:
      - mlflow_store:/mlflow
    ports:
      - "5000:5000"

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    env_file: .env
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"

volumes:
  mlflow_store:
  minio_data:
